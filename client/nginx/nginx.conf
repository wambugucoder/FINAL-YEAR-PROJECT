#if you have a higher traffic site or a dedicated instance for nginx, you want this to be set to one worker per CPU core.
#nginx provides a nice option that tells it to automatically set this to one worker per core like this
worker_processes auto;
# Allows binding worker processes automatically to available CPUs
worker_cpu_affinity auto;
# The number of simultaneous connections is limited by the number of file descriptors available on the system as each socket will open a file descriptor. If NGINX tries to open more sockets than the available file descriptors, it will lead to the Too many opened files message in the error.log.
worker_rlimit_nofile 65535;

# logging
error_log  /var/log/nginx/error.log;
error_log /var/log/nginx/error.log warn;
error_log  /var/log/nginx/error.log  notice;
error_log  /var/log/nginx/error.log  info;

pid        /var/run/nginx.pid;


events {
   worker_connections 65535;
    # This directive allows a worker to accept many connections in the queue at a time. A queue in this context simply means a sequence of data objects waiting to be processed.
    multi_accept        on;
    # With this directive worker processes will accept new connections by turn. Otherwise, all worker processes will be notified about new connections, and if volume of new connections is low, some of the worker processes may just waste system resources.
    accept_mutex        on;
    # This directive determines how long a worker should wait before accepting a new connection. Once the accept_mutex is turned on, a mutex lock is assigned to a worker for a timeframe specified by the accept_mutex_delay . When the timeframe is up, the next worker in line is ready to accept new connections.
    accept_mutex_delay  200ms;
    # This directive specifies the method to process a connection from the client. We decided to set the value to epoll because we are working on a Ubuntu platform. The epoll method is the most effective processing method for Linux platforms.
    use                 epoll;
    # This specifies the number of events that NGINX will pass to the kernel.
    epoll_events        1024;
}


#serving my production build
http {

# compression config
include /etc/nginx/compression.conf;

#server that nginx proxies request to
upstream backend{
  server server:8443;
}

 # To support larger number of server names that are defined
 server_names_hash_bucket_size  64;
# Sets the bucket size for the server names hash tables. The default value depends on the size of the processorâ€™s cache line.
 server_names_hash_max_size 512;

#Rate limit requests to 10 per seconds
 limit_req_zone $binary_remote_addr zone=mylimit:10m rate=10r/s;

 # redirect all http traffic to https
 server{
   listen 80 default_server;
   listen [::]:80 default_server ipv6only=on;
   server_name pollsapp-2021.westeurope.cloudapp.azure.com;
   root /usr/share/nginx/html;
   index index.html index.htm index.nginx-debian.html;
   return 301 https://$host$request_uri;
 }
  server {

    listen 443 ssl;
    listen [::]:443 ssl  ipv6only=on;
    server_name pollsapp-2021.westeurope.cloudapp.azure.com;
    root /usr/share/nginx/html;
    index index.html index.htm index.nginx-debian.html;



  # ssl config
    include /etc/nginx/ssl.conf;
  # security config
    include /etc/nginx/security.conf;
  # general config
    include /etc/nginx/general.conf;







}



}
