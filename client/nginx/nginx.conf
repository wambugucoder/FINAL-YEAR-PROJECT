load_module "modules/ngx_http_geoip_module.so";
#if you have a higher traffic site or a dedicated instance for nginx, you want this to be set to one worker per CPU core.
#nginx provides a nice option that tells it to automatically set this to one worker per core like this
worker_processes auto;
# Allows binding worker processes automatically to available CPUs
worker_cpu_affinity auto;
# The number of simultaneous connections is limited by the number of file descriptors available on the system as each socket will open a file descriptor. If NGINX tries to open more sockets than the available file descriptors, it will lead to the Too many opened files message in the error.log.
worker_rlimit_nofile 65535;

# logging
error_log  /var/log/nginx/error.log;
error_log /var/log/nginx/error.log warn;
error_log  /var/log/nginx/error.log  notice;
error_log  /var/log/nginx/error.log  info;

pid        /var/run/nginx.pid;


events {
   worker_connections 65535;
    # This directive allows a worker to accept many connections in the queue at a time. A queue in this context simply means a sequence of data objects waiting to be processed.
    multi_accept        on;
    # With this directive worker processes will accept new connections by turn. Otherwise, all worker processes will be notified about new connections, and if volume of new connections is low, some of the worker processes may just waste system resources.
    accept_mutex        on;
    # This directive determines how long a worker should wait before accepting a new connection. Once the accept_mutex is turned on, a mutex lock is assigned to a worker for a timeframe specified by the accept_mutex_delay . When the timeframe is up, the next worker in line is ready to accept new connections.
    accept_mutex_delay  200ms;
    # This directive specifies the method to process a connection from the client. We decided to set the value to epoll because we are working on a Ubuntu platform. The epoll method is the most effective processing method for Linux platforms.
    use                 epoll;
    # This specifies the number of events that NGINX will pass to the kernel.
    epoll_events        1024;
}


#serving my production build
http {

# compression config
# Enable Gzip compressed.
  gzip on;

  # Enable compression both for HTTP/1.0 and HTTP/1.1 (required for CloudFront).
  gzip_http_version  1.0;

  # Compression level (1-9).
  # 5 is a perfect compromise between size and cpu usage, offering about
  # 75% reduction for most ascii files (almost identical to level 9).
  gzip_comp_level    5;

  # Don't compress anything that's already small and unlikely to shrink much
  # if at all (the default is 20 bytes, which is bad as that usually leads to
  # larger files after gzipping).
  gzip_min_length    256;

  # Compress data even for clients that are connecting to us via proxies,
  # identified by the "Via" header (required for CloudFront).
  gzip_proxied       any;

  # Tell proxies to cache both the gzipped and regular version of a resource
  # whenever the client's Accept-Encoding capabilities header varies;
  # Avoids the issue where a non-gzip capable client (which is extremely rare
  # today) would display gibberish if their proxy gave them the gzipped version.
  gzip_vary          on;

  # Compress all output labeled with one of the following MIME-types.
  gzip_types
    application/atom+xml
    application/javascript
    application/json
    application/rss+xml
    application/vnd.ms-fontobject
    application/x-font-ttf
    application/x-web-app-manifest+json
    application/xhtml+xml
    application/xml
    font/opentype
    image/svg+xml
    image/x-icon
    text/css
    text/plain
    text/x-component;
  # text/html is always compressed by HttpGzipModule

    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format compression '$remote_addr - $remote_user [$time_local] '
        '"$request" $status $upstream_addr '
        '"$http_referer" "$http_user_agent" "$gzip_ratio"';



#server that nginx proxies request to
upstream backend{
  server server:8443;
}
# Connection header for WebSocket reverse proxy
    map $http_upgrade $connection_upgrade {
        default upgrade;
        ""      close;
    }

    map $remote_addr $proxy_forwarded_elem {

        # IPv4 addresses can be sent as-is
        ~^[0-9.]+$        "for=$remote_addr";

        # IPv6 addresses need to be bracketed and quoted
        ~^[0-9A-Fa-f:.]+$ "for=\"[$remote_addr]\"";

        # Unix domain socket names cannot be represented in RFC 7239 syntax
        default           "for=unknown";
    }

    map $http_forwarded $proxy_add_forwarded {

        # If the incoming Forwarded header is syntactically valid, append to it
        "~^(,[ \\t]*)*([!#$%&'*+.^_`|~0-9A-Za-z-]+=([!#$%&'*+.^_`|~0-9A-Za-z-]+|\"([\\t \\x21\\x23-\\x5B\\x5D-\\x7E\\x80-\\xFF]|\\\\[\\t \\x21-\\x7E\\x80-\\xFF])*\"))?(;([!#$%&'*+.^_`|~0-9A-Za-z-]+=([!#$%&'*+.^_`|~0-9A-Za-z-]+|\"([\\t \\x21\\x23-\\x5B\\x5D-\\x7E\\x80-\\xFF]|\\\\[\\t \\x21-\\x7E\\x80-\\xFF])*\"))?)*([ \\t]*,([ \\t]*([!#$%&'*+.^_`|~0-9A-Za-z-]+=([!#$%&'*+.^_`|~0-9A-Za-z-]+|\"([\\t \\x21\\x23-\\x5B\\x5D-\\x7E\\x80-\\xFF]|\\\\[\\t \\x21-\\x7E\\x80-\\xFF])*\"))?(;([!#$%&'*+.^_`|~0-9A-Za-z-]+=([!#$%&'*+.^_`|~0-9A-Za-z-]+|\"([\\t \\x21\\x23-\\x5B\\x5D-\\x7E\\x80-\\xFF]|\\\\[\\t \\x21-\\x7E\\x80-\\xFF])*\"))?)*)?)*$" "$http_forwarded, $proxy_forwarded_elem";

        # Otherwise, replace it
        default "$proxy_forwarded_elem";
    }

 # To support larger number of server names that are defined
 server_names_hash_bucket_size  64;
# Sets the bucket size for the server names hash tables. The default value depends on the size of the processor’s cache line.
 server_names_hash_max_size 512;

#Rate limit requests to 10 per seconds
 limit_req_zone $binary_remote_addr zone=mylimit:10m rate=10r/s;

 geoip_country /usr/share/GeoIP/GeoIP.dat;
    map $geoip_country_code $allowed_country {
        default no;
        KE yes;

    }

 # redirect all http traffic to https
 server{
   listen 80 default_server;
   listen [::]:80 default_server ipv6only=on;
   server_name poll-app.tech ;
   root /usr/share/nginx/html;
   index index.html index.htm index.nginx-debian.html;
   return 301 https://$host$request_uri;
 }
  server {
    limit_req zone=mylimit burst=20 nodelay;
    listen 443 ssl;
    listen [::]:443 ssl  ipv6only=on;
    server_name poll-app.tech ;
    root /usr/share/nginx/html;
    index index.html index.htm index.nginx-debian.html;
  # Display nginx Version number in error or http header may result in hacker to search for known vulnerability. Therefore, the version number should be removed for every http response.
        server_tokens "off";
        #charset utf-8;
        # This directive, by default, is disabled to allow small packets to wait for a specified period before they are sent at once. To allow all data to be sent at once, this directive is enabled.
        tcp_nodelay on;
        #  Because we have enabled tcp_nodelay directive, small packets are sent at once. However, if you still want to make use of John Nagle’s buffering algorithm, we can also enable the tcp_nopush to add packets to each other and send them all at once.
        tcp_nopush on;
        # Defines a timeout for reading client request body. The timeout is set only for a period between two successive read operations, not for the transmission of the whole request body. If a client does not transmit anything within this time, the 408 (Request Time-out) error is returned to the client.
        client_body_timeout 12;
        # Defines a timeout for reading client request header. If a client does not transmit the entire header within this time, the 408 (Request Time-out) error is returned to the client.
        client_header_timeout 12;
        # This directive sets the buffer size for the request body. If you plan to run the webserver on 64-bit systems, you need to set the value to 16k. If you want to run the webserver on the 32-bit system, set the value to 8k.
        client_body_buffer_size 16K;
        # Similar to the previous directive, only instead it handles the client header size. For all intents and purposes, 1K is usually a decent size for this directive not unless you're sending mayopic stuff via header i.e permissions.
        client_header_buffer_size 1k;
        # The maximum number and size of buffers for large client headers.
        large_client_header_buffers 2 1k;
        # The maximum allowed size for a client request. If the maximum size is exceeded, then Nginx will spit out a 413 error or Request Entity Too Large.
        client_max_body_size 64M;
        # Defines the maximum size of an entry in the MIME types hash tables.
        types_hash_max_size 4096;
        # The first parameter sets a timeout during which a keep-alive client connection will stay open on the server side. The zero value disables keep-alive client connections. The optional second parameter sets a value in the “Keep-Alive: timeout=time” response header field. Two parameters may differ. The “Keep-Alive: timeout=time” header field is recognized by Mozilla and Konqueror. The default is 75 seconds.
        keepalive_timeout 120s;
        # Configure a number of requests to keep alive for a specific period of time.  You can set the number of requests to 20 or 30.
        keepalive_requests 120;
        # if you want to disable keepalive connection for a specific group of browsers, use this directive.
        #keepalive_disable;
        #Sets a timeout for transmitting a response to the client. The timeout is set only between two successive write operations, not for the transmission of the whole response. If the client does not receive anything within this time, the connection is closed.
        send_timeout 75s;
        # TLS certificate and key
        ssl_certificate           /etc/ssl/certs/nginx-selfsigned.crt;
        ssl_certificate_key       /etc/ssl/private/nginx-selfsigned.key;
        # enable session resumption to improve https performance
        # http://vincent.bernat.im/en/blog/2011-ssl-session-reuse-rfc5077.html
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;
        ssl_buffer_size 1400;
        # generated using:# openssl dhparam -dsaparam -out /etc/ssl/dh4096.pem 4096
        ssl_ecdh_curve secp384r1;
        ssl_session_tickets off;
        # enables server-side protection from BEAST attacks
        # http://blog.ivanristic.com/2013/09/is-beast-still-a-threat.html
        ssl_prefer_server_ciphers on;
        # disable SSLv3(enabled by default since nginx 0.8.19) since it's less secure then TLS http://en.wikipedia.org/wiki/Secure_Sockets_Layer#SSL_3.0
        ssl_protocols  TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;
        # ciphers chosen for forward secrecy and compatibility
        # http://blog.ivanristic.com/2013/08/configuring-apache-nginx-and-openssl-for-forward-secrecy.html
        # Disabled insecure ciphers suite. For example, MD5, DES, RC4, PSK
        ssl_ciphers "ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4:@STRENGTH";
        # -!MEDIUM：exclude encryption cipher suites using 128 bit encryption.
        # -!LOW：   exclude encryption cipher suites using 64 or 56 bit encryption algorithms
        # -!EXPORT： exclude export encryption algorithms including 40 and 56 bits algorithms.
        # -!aNULL：  exclude the cipher suites offering no authentication. This is currently the anonymous DH algorithms and anonymous ECDH algorithms.
        # These cipher suites are vulnerable to a "man in the middle" attack and so their use is normally discouraged.
        # -!eNULL：exclude the "NULL" ciphers that is those offering no encryption.
        # Because these offer no encryption at all and are a security risk they are disabled unless explicitly included.
        # @STRENGTH：sort the current cipher list in order of encryption algorithm key length.
        # enable ocsp stapling (mechanism by which a site can convey certificate revocation information to visitors in a privacy-preserving, scalable manner)
        # http://blog.mozilla.org/security/2013/07/29/ocsp-stapling-in-firefox/
        #Cloudflare resolver 1dot1dot1dot1.cloudflare-dns.com
        resolver 1.1.1.1 1.0.0.1 [2606:4700:4700::1111] [2606:4700:4700::1001];
        resolver_timeout 5s;
        ssl_stapling off;
        ssl_stapling_verify on;

# config to don't allow the browser to render the page inside an frame or iframe
# and avoid clickjacking http://en.wikipedia.org/wiki/Clickjacking
# if you need to allow [i]frames, you can use SAMEORIGIN or even set an uri with ALLOW-FROM uri
# https://developer.mozilla.org/en-US/docs/HTTP/X-Frame-Options
add_header X-Frame-Options "SAMEORIGIN";
add_header X-XSS-Protection "1; mode=block";
#Handled by CDN admin
# when serving user-supplied content, include a X-Content-Type-Options: nosniff header along with the Content-Type: header,
# to disable content-type sniffing on some browsers.
# https://www.owasp.org/index.php/List_of_useful_HTTP_headers
# currently suppoorted in IE > 8 http://blogs.msdn.com/b/ie/archive/2008/09/02/ie8-security-part-vi-beta-2-update.aspx
# http://msdn.microsoft.com/en-us/library/ie/gg622941(v=vs.85).aspx
# 'soon' on Firefox https://bugzilla.mozilla.org/show_bug.cgi?id=471020
add_header X-Content-Type-Options "nosniff";
# This header enables the Cross-site scripting (XSS) filter built into most recent web browsers.
# It's usually enabled by default anyway, so the role of this header is to re-enable the filter for
# this particular website if it was disabled by the user.
# https://www.owasp.org/index.php/List_of_useful_HTTP_headers
add_header X-XSS-Protection "1; mode=block";

add_header Referrer-Policy "no-referrer-when-downgrade";
# with Content Security Policy (CSP) enabled(and a browser that supports it(http://caniuse.com/#feat=contentsecuritypolicy),
# you can tell the browser that it can only download content from the domains you explicitly allow
# http://www.html5rocks.com/en/tutorials/security/content-security-policy/
# https://www.owasp.org/index.php/Content_Security_Policy
# I need to change our application code so we can increase security by disabling 'unsafe-inline' 'unsafe-eval'
# directives for css and js(if you have inline css or js, you will need to keep it too).
# more: http://www.html5rocks.com/en/tutorials/security/content-security-policy/#inline-code-considered-harmful
# add_header Content-Security-Policy "default-src 'self' http: https: data: blob: 'unsafe-inline'";
#For Clouflare users comment this out as it's handle from the admin UI
add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload";
# Prevent search engine indexing
#add_header  X-Robots-Tag "noindex, nofollow, nosnippet, noarchive";


 # enable nginx metrics for the prometheus scraper
location /nginx_status {
            stub_status on;
            access_log  off;
            allow all;  # REPLACE with your access policy


 }
# restrict methods
 if ($request_method !~ ^(GET|POST|PUT|DELETE)$) {
        return '405';
    }

 if ($allowed_country = no) {
            return 444;
        }

#Queueing with No Delay
location / {
    index  index.html index.htm index.nginx-debian.html;

    #to redirect allrequests to index.html
    #useful when using react router
    try_files $uri $uri/ /index.html;
  }

  # redirect server error pages
error_page   500 502 503 504  /50x.html;

  location = /50x.html {
   root   /var/www;
  }

  location ~* \.(?:manifest|appcache|html?|xml|json)$ {
            expires -1;
            # access_log logs/static.log; # I don't usually include a static log
        }


# Media: images, icons, video, audio, HTC
        location ~* \.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|ogg|ogv|webm|htc)$ {
          expires 1M;
          access_log off;
          add_header Cache-Control "public";
        }

        location ~* \.(?:css|js)$ {
            try_files $uri =404;
            expires 1y;
            access_log off;
            add_header Cache-Control "public";
        }



  #setting up a reverse proxy for my backend
   location /api {

       proxy_pass https://backend;
       proxy_http_version                 1.1;
       proxy_cache_bypass                 $http_upgrade;
       # Proxy headers
       proxy_set_header Upgrade           $http_upgrade;
       proxy_set_header Connection        $connection_upgrade;
       proxy_set_header Host              $host;
       proxy_set_header X-Real-IP         $remote_addr;
       proxy_set_header Forwarded         $proxy_add_forwarded;
       proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
       proxy_set_header X-Forwarded-Proto $scheme;
       proxy_set_header X-Forwarded-Host  $host;
       proxy_set_header X-Forwarded-Port  $server_port;
       # Proxy timeouts
       proxy_connect_timeout              60s;
       proxy_send_timeout                 60s;
       proxy_read_timeout                 60s;


    }





}



}
